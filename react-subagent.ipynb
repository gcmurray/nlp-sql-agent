{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9cf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableConfig\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, ValidationError, ValidationInfo, field_validator, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import add_messages, START, END, MessagesState, StateGraph\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.config import get_stream_writer\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langgraph.prebuilt import InjectedState, create_react_agent, ToolNode\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langchain.chains.sql_database.query import create_sql_query_chain\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d9c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class State(AgentState):\n",
    "# customize state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4ffd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat model\n",
    "llm = ChatOllama(model=\"mistral:latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9624aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# SQL database ---------------------------------------\n",
    "db = SQLDatabase.from_uri(\n",
    "    f\"postgresql+psycopg2://postgres:password@localhost:5432/ta_database\",\n",
    ")\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "get_schema_node = ToolNode([get_schema_tool], name=\"get_schema\")\n",
    "\n",
    "run_query_tool = next(tool for tool in tools if tool.name == \"sql_db_query\")\n",
    "run_query_node = ToolNode([run_query_tool], name=\"run_query\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# Example: create a predetermined tool call\n",
    "def list_tables(state: MessagesState):\n",
    "    tool_call = {\n",
    "        \"name\": \"sql_db_list_tables\",\n",
    "        \"args\": {},\n",
    "        \"id\": \"abc123\",\n",
    "        \"type\": \"tool_call\",\n",
    "    }\n",
    "    tool_call_message = AIMessage(content=\"\", tool_calls=[tool_call])\n",
    "\n",
    "    list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "    tool_message = list_tables_tool.invoke(tool_call)\n",
    "    response = AIMessage(f\"Available tables: {tool_message.content}\")\n",
    "\n",
    "    return {\"messages\": [tool_call_message, tool_message, response]}\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Example: force a model to create a tool call\n",
    "def call_get_schema(state: MessagesState):\n",
    "    # Note that LangChain enforces that all models accept `tool_choice=\"any\"`\n",
    "    # as well as `tool_choice=<string name of tool>`.\n",
    "    llm_with_tools = llm.bind_tools([get_schema_tool], tool_choice=\"any\")\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "generate_query_system_prompt = \"\"\"\n",
    "You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run,\n",
    "then look at the results of the query and return the answer. Unless the user\n",
    "specifies a specific number of examples they wish to obtain, always limit your\n",
    "query to at most {top_k} results.\n",
    "\n",
    "You can order the results by a relevant column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the relevant columns given the question.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\"\"\".format(\n",
    "    dialect=db.dialect,\n",
    "    top_k=5,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def generate_query(state: MessagesState):\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": generate_query_system_prompt,\n",
    "    }\n",
    "    # We do not force a tool call here, to allow the model to\n",
    "    # respond naturally when it obtains the solution.\n",
    "    llm_with_tools = llm.bind_tools([run_query_tool])\n",
    "    response = llm_with_tools.invoke([system_message] + state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "check_query_system_prompt = \"\"\"\n",
    "You are a SQL expert with a strong attention to detail.\n",
    "Double check the {dialect} query for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "If there are any of the above mistakes, rewrite the query. If there are no mistakes,\n",
    "just reproduce the original query.\n",
    "\n",
    "You will call the appropriate tool to execute the query after running this check.\n",
    "\"\"\".format(dialect=db.dialect)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def check_query(state: MessagesState):\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": check_query_system_prompt,\n",
    "    }\n",
    "\n",
    "    # Generate an artificial user message to check\n",
    "    tool_call = state[\"messages\"][-1].tool_calls[0]\n",
    "    user_message = {\"role\": \"user\", \"content\": tool_call[\"args\"][\"query\"]}\n",
    "    llm_with_tools = llm.bind_tools([run_query_tool], tool_choice=\"any\")\n",
    "    response = llm_with_tools.invoke([system_message, user_message])\n",
    "    response.id = state[\"messages\"][-1].id\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[END, \"check_query\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if not last_message.tool_calls:\n",
    "        return END\n",
    "    else:\n",
    "        return \"check_query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc758c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# embeddings for vector store retriever -----------------\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# the vector store, course content\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"asm_z80\",\n",
    "    embedding_function=embeddings,\n",
    "    host=\"localhost\",\n",
    ")\n",
    "rag_prompt = PromptTemplate(template=\"\"\"Given the question and content, decide if the content is relevant to the question.\n",
    "                            if it is, respond with a summary of the documents in the content. If not, respond with ONLY the word 'rephrase'.\n",
    "                            Question: {question}\n",
    "                            Content: {context}\n",
    "                            Response: \"\"\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "\n",
    "# -------- RAG Tool ----------------\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": compression_retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f9f6e",
   "metadata": {},
   "source": [
    "## Build the SQL Subgraph / Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e809cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(list_tables)\n",
    "builder.add_node(call_get_schema)\n",
    "builder.add_node(get_schema_node, \"get_schema\")\n",
    "builder.add_node(generate_query)\n",
    "builder.add_node(check_query)\n",
    "builder.add_node(run_query_node, \"run_query\")\n",
    "\n",
    "builder.add_edge(START, \"list_tables\")\n",
    "builder.add_edge(\"list_tables\", \"call_get_schema\")\n",
    "builder.add_edge(\"call_get_schema\", \"get_schema\")\n",
    "builder.add_edge(\"get_schema\", \"generate_query\")\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_query\",\n",
    "    should_continue,\n",
    ")\n",
    "builder.add_edge(\"check_query\", \"run_query\")\n",
    "builder.add_edge(\"run_query\", \"generate_query\")\n",
    "\n",
    "sql_agent = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d53bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        +-----------+                    \n",
      "                        | __start__ |                    \n",
      "                        +-----------+                    \n",
      "                              *                          \n",
      "                              *                          \n",
      "                              *                          \n",
      "                       +-------------+                   \n",
      "                       | list_tables |                   \n",
      "                       +-------------+                   \n",
      "                              *                          \n",
      "                              *                          \n",
      "                              *                          \n",
      "                     +-----------------+                 \n",
      "                     | call_get_schema |                 \n",
      "                     +-----------------+                 \n",
      "                              *                          \n",
      "                              *                          \n",
      "                              *                          \n",
      "                        +------------+                   \n",
      "                        | get_schema |                   \n",
      "                        +------------+                   \n",
      "                              *                          \n",
      "                              *                          \n",
      "                              *                          \n",
      "                      +----------------+                 \n",
      "                      | generate_query |                 \n",
      "                     .+----------------+**               \n",
      "                .....         .           ****           \n",
      "             ...              .               ****       \n",
      "          ...                 .                   ****   \n",
      "+---------+           +-------------+                 ***\n",
      "| __end__ |           | check_query |                **  \n",
      "+---------+           +-------------+              **    \n",
      "                                   ***           **      \n",
      "                                      *        **        \n",
      "                                       **    **          \n",
      "                                    +-----------+        \n",
      "                                    | run_query |        \n",
      "                                    +-----------+        \n"
     ]
    }
   ],
   "source": [
    "sql_agent.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b98407",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def agent_SQL(query: str, state: Annotated[dict, InjectedState]):\n",
    "    \"\"\"A tool for searching relevant documents for teaching in the course.\n",
    "    \n",
    "    Args:\n",
    "        query: the query for the SQL agent.\n",
    "    \"\"\"\n",
    "    response = sql_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "    return response\n",
    "\n",
    "@tool\n",
    "def agent_RAG(query: str, state: Annotated[dict, InjectedState]):\n",
    "    \"\"\"A tool for searching relevant documents for teaching in the course.\n",
    "    \n",
    "    Args:\n",
    "        query: the query for the RAG agent.\n",
    "    \"\"\"\n",
    "    response = rag_chain.invoke(query)\n",
    "    return response\n",
    "\n",
    "tools = [agent_SQL, agent_RAG]\n",
    "\n",
    "sys_prompt = \"You are a teaching assistant designed to help students with their lessons and grades. Use agent_SQL for data related to students, assignments, or grades, and use agent_RAG for teaching course materials and lessons.\"\n",
    "memory = MemorySaver()\n",
    "agent_supervisor = create_react_agent(model=llm, prompt=sys_prompt, tools=tools, state_schema=AgentState, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4e475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "               *              \n",
      "               *              \n",
      "               *              \n",
      "          +-------+           \n",
      "          | agent |           \n",
      "          +-------+.          \n",
      "          .         .         \n",
      "        ..           ..       \n",
      "       .               .      \n",
      "+---------+         +-------+ \n",
      "| __end__ |         | tools | \n",
      "+---------+         +-------+ \n"
     ]
    }
   ],
   "source": [
    "agent_supervisor.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f025e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Alice Smith's grade for Project 1?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  agent_SQL (18b5bed2-c458-48fc-b8cf-cd68ab6a1485)\n",
      " Call ID: 18b5bed2-c458-48fc-b8cf-cd68ab6a1485\n",
      "  Args:\n",
      "    query: SELECT grade FROM projects WHERE student = 'Alice Smith' AND projectName = 'Project 1';\n",
      "  agent_SQL (54b3eb5b-cea5-4f84-9737-2dc436faa941)\n",
      " Call ID: 54b3eb5b-cea5-4f84-9737-2dc436faa941\n",
      "  Args:\n",
      "    query: SELECT grade FROM projects WHERE student = 'Alice Smith' AND projectName = 'Project 1';\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: agent_SQL\n",
      "\n",
      "Error: RuntimeError('generator raised StopIteration')\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  agent_SQL (beb29900-9e31-42df-bd6c-556b4ec36586)\n",
      " Call ID: beb29900-9e31-42df-bd6c-556b4ec36586\n",
      "  Args:\n",
      "    query: SELECT grade FROM projects WHERE student = 'Alice Smith' AND projectName = 'Project 1';\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: agent_SQL\n",
      "\n",
      "Error: RuntimeError('generator raised StopIteration')\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " It seems that there might be an issue with the database query. Here's a possible corrected version of the SQL command:\n",
      "\n",
      "```sql\n",
      "SELECT grade FROM projects WHERE student = 'Alice Smith' AND projectName = 'Project 1';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Alice Smith's grade for Project 1?\"\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"greg\"}}\n",
    "\n",
    "for chunk in agent_supervisor.stream({\"messages\": [{\"role\": \"user\", \"content\": input_message}]}, stream_mode=\"values\", config=config):\n",
    "    #print(chunk)\n",
    "    for state_key, state_value in chunk.items():\n",
    "       if state_key == \"messages\":\n",
    "           state_value[-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
