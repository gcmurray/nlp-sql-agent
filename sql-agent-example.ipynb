{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b8a02c",
   "metadata": {},
   "source": [
    "## Core Components\n",
    "First we build our llm, our SQL database, our embedding model, and our document vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158d268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "llm = ChatOllama(model=\"mistral:latest\")\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    f\"postgresql+psycopg2://postgres:password@localhost:5432/postgres\",\n",
    ")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"asm_z80\",\n",
    "    embedding_function=embeddings,\n",
    "    host=\"localhost\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688aa214",
   "metadata": {},
   "source": [
    "## Tools\n",
    "Build the tools: the retrieve tool is used to get RAG content, the SQLDatabaseToolkit provides query related tools for the SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cacaf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_course_material\",\n",
    "    \"Search and return information about the course lessons and reading material.\",\n",
    ")\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "sql_tools = toolkit.get_tools()\n",
    "rag_tools = [retriever_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ec48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are a teacher, answering students questions.\"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. If teaching the student, lead the student \"\n",
    "        \"to the answer rather than giving the answer straight away.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fee8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sup_sys_msg = SystemMessage(content=\"\"\"You are a teacher agent that has access to a teaching_agent and a database_agent.\n",
    "              Incorporate the responses from the agents to answer the student questions. For grade related queries, use the database_expert agent.\n",
    "              For course content, use the teaching_expert agent.\"\"\")\n",
    "\n",
    "sql_sys_msg = SystemMessage(content=\"\"\"\n",
    "You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run,\n",
    "then look at the results of the query and return the answer. Unless the user\n",
    "specifies a specific number of examples they wish to obtain, always limit your\n",
    "query to at most {top_k} results.\n",
    "\n",
    "You can order the results by a relevant column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the relevant columns given the question.\n",
    "\n",
    "You MUST double check your query before executing it. If you get an error while\n",
    "executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you\n",
    "can query. Do NOT skip this step.\n",
    "\n",
    "Then you should query the schema of the most relevant tables.\n",
    "\"\"\".format(\n",
    "    dialect=\"PostgreSQL\",\n",
    "    top_k=5,\n",
    "))\n",
    "\n",
    "ta_sys_msg = SystemMessage(content=\"\"\"You are a teaching assistant agent answering student queries\n",
    "                                      about course material. Use the retriever_tool on the query\n",
    "                                      to gather documents relevant to the query. ALWAYS use the tool.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9272281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver  # an in-memory checkpointer\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "sql_memory = MemorySaver()\n",
    "\n",
    "sql_agent = create_react_agent(\n",
    "    llm.bind_tools(sql_tools), sql_tools, prompt=sql_sys_msg, checkpointer=sql_memory,\n",
    "    name=\"database_expert\")\n",
    "\n",
    "ta_memory = MemorySaver()\n",
    "\n",
    "ta_agent = create_react_agent(llm.bind_tools(rag_tools), rag_tools, checkpointer=ta_memory,\n",
    "                              prompt=ta_sys_msg,\n",
    "                              name=\"teaching_expert\")\n",
    "\n",
    "workflow = create_supervisor(\n",
    "    [sql_agent, ta_agent],\n",
    "    model=llm,\n",
    "    prompt=sup_sys_msg,\n",
    ")\n",
    "\n",
    "supervisor_memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=supervisor_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dcee791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             +-----------+                               \n",
      "                             | __start__ |                               \n",
      "                             +-----------+                               \n",
      "                                    *                                    \n",
      "                                    *                                    \n",
      "                                    *                                    \n",
      "                            +------------+                               \n",
      "                            | supervisor |*                              \n",
      "                         ...+------------+ ****                          \n",
      "                     ....           .          ****                      \n",
      "                 ....               .              ****                  \n",
      "              ...                   .                  ***               \n",
      "+-----------------+           +---------+           +-----------------+  \n",
      "| database_expert |           | __end__ |           | teaching_expert |  \n",
      "+-----------------+           +---------+           +-----------------+  \n"
     ]
    }
   ],
   "source": [
    "app.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "038e3145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the content of our course?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: transfer_to_teaching_expert\n",
      "\n",
      "Successfully transferred to teaching_expert\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: transfer_back_to_supervisor\n",
      "\n",
      "Successfully transferred back to supervisor\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      " I have successfully returned the response to the teaching expert and will now work on preparing the course content as described. Thank you!\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is the content of our course?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"greg\"}}\n",
    "\n",
    "for chunk in app.stream({\"messages\": [{\"role\": \"user\", \"content\": input_message}]}, stream_mode=\"values\", config=config):\n",
    "    for state_key, state_value in chunk.items():\n",
    "        if state_key == \"messages\":\n",
    "            state_value[-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44cefc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the content of our course?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "Tool Calls:\n",
      "  transfer_to_teaching_expert (8b13d222-9a06-42f8-aba5-a511c4502b5b)\n",
      " Call ID: 8b13d222-9a06-42f8-aba5-a511c4502b5b\n",
      "  Args:\n",
      "    question: What is the content of our course?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: transfer_to_teaching_expert\n",
      "\n",
      "Successfully transferred to teaching_expert\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: teaching_expert\n",
      "\n",
      " The content of our course covers the following topics:\n",
      "\n",
      "1. Introduction to Artificial Intelligence (AI) and its importance in today's world.\n",
      "2. Fundamentals of Machine Learning (ML), including supervised learning, unsupervised learning, reinforcement learning, and deep learning.\n",
      "3. Key concepts in data preprocessing, such as normalization, feature extraction, and dimensionality reduction.\n",
      "4. Advanced topics in ML algorithms, including Support Vector Machines (SVMs), Random Forests, Gradient Boosting, Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformers.\n",
      "5. Practical applications of AI/ML in various industries, such as finance, healthcare, automotive, and retail.\n",
      "6. Ethics and responsible AI practices, including bias mitigation, privacy protection, and fairness.\n",
      "7. Hands-on projects using popular ML libraries such as TensorFlow, PyTorch, Scikit-learn, and Keras to reinforce learning and gain practical experience.\n",
      "8. Final project to apply the knowledge gained throughout the course to a real-world AI/ML problem.\n",
      "\n",
      "This comprehensive curriculum provides students with a strong foundation in AI and ML principles and prepares them for careers in data science, machine learning engineering, AI research, or related fields.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: teaching_expert\n",
      "\n",
      "Transferring back to supervisor\n",
      "Tool Calls:\n",
      "  transfer_back_to_supervisor (40556cbf-4bd0-4429-9394-140abfa2a1fb)\n",
      " Call ID: 40556cbf-4bd0-4429-9394-140abfa2a1fb\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: transfer_back_to_supervisor\n",
      "\n",
      "Successfully transferred back to supervisor\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      " I have successfully returned the response to the teaching expert and will now work on preparing the course content as described. Thank you!\n"
     ]
    }
   ],
   "source": [
    "state = app.get_state(config).values\n",
    "\n",
    "for message in state[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5492b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the lesson for day 6?\"\n",
    "        }\n",
    "    ]\n",
    "}, config=config)\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
